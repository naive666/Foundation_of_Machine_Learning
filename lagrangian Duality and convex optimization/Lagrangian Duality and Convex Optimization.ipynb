{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notation\n",
    "## Convex Set  \n",
    "### Definition  \n",
    "- A set $C$ is said to be convex if for any $x_1, x_2 \\in C$, and any $0 \\leq \\theta \\leq 1$,  \n",
    "$$\\theta x_1 + (1 - \\theta)x_2 \\in C $$  \n",
    "<div align=\"center\"><img src = \"./convex set.jpg\" width = '500' height = '100' align = center /></div>  \n",
    "\n",
    "## Convex Function  \n",
    "### Definition  \n",
    "- A function $f : R_n \\to R$ is convex if dom$f$ is a convex set and if for all $x, y \\in $dom$f$, and $0 \\leq \\theta \\leq 1$, we have \n",
    "$$f(\\theta x+(1-\\theta) y) \\leqslant \\theta f(x)+(1-\\theta) f(y)$$  \n",
    "<div align=\"center\"><img src = \"./convex function.jpg\" width = '500' height = '100' align = center /></div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strictly Convex  \n",
    "A function $f$ is **strictly convex** if the line segment connecting any two points on the graph of $f$ lies strictly above the graph (excluding the endpoints).  \n",
    "\n",
    "Consequences for optimization:  \n",
    "- **convex**: if there is a local minimum, then it is a **global** minimum  \n",
    "- **convex**: if there is a local minimum, then it is the **unique global** minumum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Optimization  Problem  \n",
    "##  General Optimization Problem: Standard Form  \n",
    "$$\\begin{array}{ll}\n",
    "\\operatorname{minimize} & f_{0}(x) \\\\\n",
    "\\text { subject to } & f_{i}(x) \\leqslant 0, \\quad i=1, \\ldots, m \\\\\n",
    "& h_{i}(x)=0, \\quad i=1, \\ldots p\n",
    "\\end{array}$$  \n",
    "where $x \\in R_n$ are the optimization variables and $f_0$ is the objective function.  \n",
    "Assume **Domain** $\\mathcal{D}=\\bigcap_{i=0}^{m} \\operatorname{dom} f_{i} \\cap \\bigcap_{i=1}^{p} \\operatorname{dom} h_{i}$  \n",
    "## More Terminologies  \n",
    "- The set of points satisfying the constraints is called the **feasible set**\n",
    "- A point $x$ in the feasible set is called a **feasible point**  \n",
    "- If $x$ is feasible and $f_i(x) = 0$, then we say the inequality constraint $f_i(x) \\leq 0$ is active at x  \n",
    "- The optimal value $p^*$ of the problem is defined as  \n",
    "$$p^{*}=\\inf \\left\\{f_{0}(x) \\mid x \\text { satisfies all constraints }\\right\\}$$  \n",
    "- $x^∗$ is an optimal point (or a solution to the problem) if $x^∗$ is feasible and $f(x^∗) = p^∗$\n",
    "## Do we need equality constraints?  \n",
    "- Consider an equality-constrained problem  \n",
    "$$\\begin{array}{ll}\n",
    "\\operatorname{minimize} & f_{0}(x) \\\\\n",
    "\\text { subject to } & h(x)=0\n",
    "\\end{array}$$  \n",
    "- Can be rewritten as  \n",
    "$$\\begin{array}{ll}\n",
    "\\operatorname{minimize} & f_{0}(x) \\\\\n",
    "\\text { subject to } & h(x) \\leqslant 0 \\\\\n",
    "& -h(x) \\leqslant 0\n",
    "\\end{array}$$  \n",
    "- For simplicity, we’ll drop equality contraints from this presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lagrangian Duality: Convexity not required  \n",
    "## The Lagrangian  \n",
    "The **Lagrangian** for this optimization problem is  \n",
    "$$L(x, \\lambda)=f_{0}(x)+\\sum_{i=1}^{m} \\lambda_{i} f_{i}(x)$$  \n",
    "$\\lambda_i$s are called Lagrange multipliers (also called the dual variables).  \n",
    "- Supremum over Lagrangian gives back encoding of objective and constraints  \n",
    "$$\\begin{aligned}\n",
    "\\sup _{\\lambda \\succeq 0} L(x, \\lambda) &=\\sup _{\\lambda \\succeq 0}\\left(f_{0}(x)+\\sum_{i=1}^{m} \\lambda_{i} f_{i}(x)\\right) \\\\\n",
    "&=\\left\\{\\begin{array}{ll}\n",
    "f_{0}(x) & \\text { when } f_{i}(x) \\leqslant 0 \\text { all } i \\\\\n",
    "\\infty & \\text { otherwise }\n",
    "\\end{array}\\right.\n",
    "\\end{aligned}$$\n",
    "As we can choose any $\\lambda \\geq 0$ such that we can attain supremum, thus if some $f_i(x) \\geq 0$, we could set the corresponding $\\lambda_i$ to infinity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Equivalent **Primal Form** of optimization problem is:  \n",
    "$$p^{*}=\\inf _{x} \\sup _{\\lambda \\succeq 0} L(x, \\lambda)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get the **Lagrangian dual problem**  \n",
    "$$d^{*}=\\sup _{\\lambda \\succeq 0} \\inf _{x} L(x, \\lambda)$$  \n",
    "## Weak Duality : $p^* \\geq d^*$ for any optimization problem  \n",
    "- Weak Max-Min Inequality  \n",
    "- Theorem: For any $f : W \\times Z \\to R$, we have  \n",
    "$$\\sup _{z \\in Z} \\inf _{w \\in W} f(w, z) \\leqslant \\inf _{w \\in W} \\sup _{z \\in Z} f(w, z)$$\n",
    "**Proof**  \n",
    "$$\\inf _{w \\in W} f(w, z_0) \\leqslant f(w_0, z_0) \\leqslant \\sup _{z \\in Z} f(w, z_0)$$  \n",
    "since $\\inf _{w \\in W} f\\left(w, z_{0}\\right) \\leqslant \\sup _{z \\in Z} f\\left(w_{0}, z\\right)$ for all $w$ and $z$, we must have  \n",
    "$$\\sup _{z_{0} \\in Z} \\inf _{w \\in W} f\\left(w, z_{0}\\right) \\leqslant \\inf _{w_{0} \\in W} \\sup _{z \\in Z} f\\left(w_{0}, z\\right)$$  \n",
    "- For any optimization problem (not just convex), weak max-min inequality implies weak duality:\n",
    "$$\\begin{aligned}\n",
    "p^{*}=& \\inf _{x} \\sup _{\\lambda \\succeq 0}\\left[f_{0}(x)+\\sum_{i=1}^{m} \\lambda_{i} f_{i}(x)\\right] \\\\\n",
    "& \\geqslant \\sup _{\\lambda \\succeq 0, v} \\inf _{x}\\left[f_{0}(x)+\\sum_{i=1}^{m} \\lambda_{i} f_{i}(x)\\right]=d^{*}\n",
    "\\end{aligned}$$  \n",
    "- For convex problems, we often have strong duality: $p^∗ = d^∗$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Lagrange Dual Function\n",
    "$$d^{*}=\\sup _{\\lambda \\succeq 0} \\inf _{x} L(x, \\lambda)$$  \n",
    "- Definition  \n",
    "The Lagrange dual function (or just dual function) is:  \n",
    "$$g(\\lambda)=\\inf _{x} L(x, \\lambda)=\\inf _{x}\\left(f_{0}(x)+\\sum_{i=1}^{m} \\lambda_{i} f_{i}(x)\\right)$$\n",
    "- The dual function is always **concave**   \n",
    "### The Lagrange Dual Problem: Search for Best Lower Bound  \n",
    "Let's write weak duality as:  \n",
    "$$p^{*} \\geqslant \\sup _{\\lambda \\succeq 0} g(\\lambda)=d^{*}$$  \n",
    "So for any $\\lambda$ with $\\lambda \\geqslant 0$, Lagrange dual function gives a **lower bound on optimal solution**  \n",
    "- The Lagrange dual problem is a search for best lower bound on $p^∗$:\n",
    "$$\\begin{array}{ll}\n",
    "\\text { maximize } & g(\\lambda) \\\\\n",
    "\\text { subject to } & \\lambda \\succeq 0\n",
    "\\end{array}$$  \n",
    "- $\\lambda$ is **dual feasible** if $\\lambda \\succeq 0$ and $g(\\lambda) > -\\infty$  \n",
    "- $\\lambda^∗$ **dual optimal** or optimal Lagrange multipliers if they are optimal for the Lagrange dual problem.   \n",
    "- Lagrange dual problem often easier to solve (simpler constraints). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convex Optimization\n",
    "## Standard Form\n",
    "$$\\begin{array}{ll}\n",
    "\\operatorname{minimize} & f_{0}(x) \\\\\n",
    "\\text { subject to } & f_{i}(x) \\leqslant 0, \\quad i=1, \\ldots, m\n",
    "\\end{array}$$  \n",
    "where $f_0, f_1, ... , f_m$ are convex functions  \n",
    "## Strong Duality for Convex Problems\n",
    "- For a convex optimization problems, we usually have strong duality, but not always  \n",
    "  -  Convex problem without strong duality  \n",
    "    $$\\begin{array}{cl}\n",
    "\\operatorname{minimize} & e^{-x} \\\\\n",
    "\\text { subject to } & x^{2} / y \\leqslant 0 \\\\\n",
    "& y>0\n",
    "\\end{array}$$  \n",
    "- The additional conditions needed are called constraint qualiﬁcations\n",
    "## Slater’s Constraint Qualiﬁcations for Strong Duality\n",
    "- Suﬃcient conditions for strong duality in a convex problem  \n",
    "- Roughly: the problem must be strictly feasible.  \n",
    "Qualiﬁcations when problem domain $D \\subset  R^n$ is an open set:  \n",
    "- **Strict feasibility is sufficient** $\\left(\\exists x, f_{i}(x)<0 \\text { for } i=1, \\ldots, m\\right)$  \n",
    "- For any affine inequality constraints, $f_i(x) \\leqslant 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complementary Slackness  \n",
    "- Consider a general optimization problem (i.e. not necessarily convex)  \n",
    "- If we have strong duality, we get an interesting relationship between  \n",
    "  - the optimal Lagrange multiplier $\\lambda_i^*$ and  \n",
    "  - the $i$th constraint at the optimum: $f_i(x^*)$  \n",
    " - Such relationship is called \"Complementary Slackness\"  \n",
    "$$\\lambda_i^* f_i(x^*) = 0$$  \n",
    "- Always have Lagrange multiplier is zero or constraint is active at optimum or both  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
